# GenAI IDP Accelerator - Terraform Examples

This directory contains comprehensive examples demonstrating how to deploy the GenAI IDP Accelerator using Terraform. Each example is designed to be easily deployable with `terraform init`, `terraform plan`, and `terraform apply` after setting up the `terraform.tfvars` file.

## üöÄ Quick Start

1. **Choose your processing pattern** from the examples below
2. **Navigate to the example directory**
3. **Copy the example configuration**: `cp terraform.tfvars.example terraform.tfvars`
4. **Customize the variables** in `terraform.tfvars`
5. **Deploy**: `terraform init && terraform plan && terraform apply`

## üìÅ Available Examples

### 1. **Bedrock LLM Processor** (`bedrock-llm-processor/`)

**Best for**: Flexible document processing with foundation models

- **Processing**: Multi-stage pipeline with Claude/Nova models
- **Features**: Classification, extraction, summarization, assessment, evaluation
- **Setup**: Fully automated deployment
- **Customization**: Complete control over processing logic

**Key Features**:

- ‚úÖ Web UI with CloudFront distribution
- ‚úÖ Knowledge Base integration for RAG
- ‚úÖ Assessment functions for quality measurement
- ‚úÖ Evaluation against baseline documents
- ‚úÖ Analytics and reporting environment
- ‚úÖ Configurable model selection (Claude, Nova)

### 2. **BDA Processor** (`bda-processor/`)

**Best for**: Standard document types with well-defined schemas

- **Processing**: Managed service with built-in document understanding
- **Features**: BDA integration, summarization, evaluation, reporting
- **Setup**: Requires existing BDA project configuration
- **Customization**: Schema-based with predefined document classes

**Key Features**:

- ‚úÖ Bedrock Data Automation integration
- ‚úÖ Web UI for document management
- ‚úÖ Evaluation against baseline documents
- ‚úÖ Analytics and reporting environment
- ‚úÖ Configurable document schemas

### 3. **SageMaker UDOP Processor** (`sagemaker-udop-processor/`)

**Best for**: Specialized document processing with custom models

- **Processing**: Fine-tuned UDOP models for classification + Bedrock for extraction
- **Features**: Custom model deployment, assessment, evaluation, reporting
- **Setup**: Requires trained UDOP model artifacts
- **Customization**: Custom model training and deployment

**Key Features**:

- ‚úÖ SageMaker endpoint deployment with auto-scaling
- ‚úÖ Custom UDOP model integration
- ‚úÖ Assessment functions for quality measurement
- ‚úÖ Evaluation against baseline documents
- ‚úÖ Analytics and reporting environment
- ‚úÖ GPU-optimized instance types

### 4. **Processing Environment** (`processing-environment/`)

**Best for**: Core infrastructure without processors

- **Purpose**: Demonstrates the core processing environment module
- **Features**: S3 buckets, DynamoDB tables, Lambda functions, evaluation, reporting
- **Use Case**: Building custom processors or understanding core components

### 5. **Processing Environment API** (`processing-environment-api/`)

**Best for**: Standalone API deployment

- **Purpose**: Demonstrates the decoupled API module
- **Features**: AppSync GraphQL API, Cognito authentication, real-time subscriptions
- **Use Case**: Adding API functionality to existing processing environments

### 6. **Core Tables** (`core-tables/`)

**Best for**: Shared DynamoDB tables

- **Purpose**: Demonstrates shared table deployment
- **Features**: Configuration and tracking tables with encryption
- **Use Case**: Multi-processor deployments with shared state

### 7. **User Identity Standalone** (`user-identity-standalone/`)

**Best for**: Authentication infrastructure

- **Purpose**: Demonstrates user identity management
- **Features**: Cognito User Pool, Identity Pool, admin user creation
- **Use Case**: Adding authentication to custom applications

## üéØ New Features in All Examples

### **Assessment Functions** üîç

- **Purpose**: Document quality assessment and validation
- **Models**: Configurable Bedrock models (Claude Haiku recommended)
- **Usage**: Set `enable_assessment = true` in terraform.tfvars (defaults to `false`)
- **Benefits**: Real-time quality scoring and feedback

### **Evaluation Functions** üìä

- **Purpose**: Compare processing results against baseline documents
- **Models**: Configurable Bedrock models for evaluation
- **Usage**: Set `enable_evaluation = true` and provide baseline bucket (defaults to `false`)
- **Benefits**: Accuracy measurement and performance tracking

### **Reporting Environment** üìà

- **Purpose**: Analytics and metrics storage in Parquet format
- **Components**: S3 bucket, Glue database, 4 analytical tables
- **Usage**: Set `enable_reporting = true` in terraform.tfvars (defaults to `false`)
- **Benefits**: Athena-ready analytics, cost tracking, performance metrics

### **Enhanced Monitoring** üìã

- **CloudWatch Dashboards**: Comprehensive metrics and alarms
- **Custom Metrics**: Processing time, accuracy, cost per document
- **Log Aggregation**: Centralized logging with configurable retention
- **Performance Tracking**: Throughput and latency monitoring

## üîß Configuration Guide

### **Basic Configuration**

```hcl
# terraform.tfvars
region = "us-east-1"
prefix = "my-idp"

# Enable optional features (all default to false)
enable_assessment = true
enable_evaluation = true
enable_reporting  = true

# Model configuration
assessment_model_id = "anthropic.claude-3-haiku-20240307-v1:0"
evaluation_model_id = "anthropic.claude-3-haiku-20240307-v1:0"
```

### **Advanced Configuration**

```hcl
# Performance tuning
max_processing_concurrency = 100
classification_max_workers = 20
extraction_max_workers     = 20

# Security configuration
enable_kms_encryption = true
vpc_deployment       = false

# Web UI configuration
enable_web_ui           = true
cloudfront_price_class  = "PriceClass_100"
enable_geo_restriction  = false
```

## üìã Prerequisites

### **AWS Requirements**

- AWS CLI configured with appropriate permissions
- Terraform >= 1.0 installed
- Docker installed (for Lambda layer building)

### **Bedrock Model Access**

**‚ö†Ô∏è Important**: Enable model access in AWS Console before deployment:

1. Navigate to **Amazon Bedrock** ‚Üí **Model access**
2. Request access to required models:
   - **Claude 3 Sonnet**: `anthropic.claude-3-sonnet-20240229-v1:0`
   - **Claude 3 Haiku**: `anthropic.claude-3-haiku-20240307-v1:0`
   - **Nova Pro**: `us.amazon.nova-pro-v1:0`
   - **Titan Text Express**: `amazon.titan-text-express-v1`

### **Service Quotas**

Ensure adequate quotas for:

- Lambda concurrent executions (recommended: 1000+)
- Step Functions state machines (recommended: 100+)
- SageMaker endpoints (for UDOP processor)
- Bedrock model invocations

## üöÄ Deployment Steps

### **1. Choose Your Example**

```bash
cd examples/bedrock-llm-processor  # or your preferred example
```

### **2. Configure Variables**

```bash
cp terraform.tfvars.example terraform.tfvars
nano terraform.tfvars  # Edit with your values
```

### **3. Deploy Infrastructure**

```bash
terraform init
terraform plan
terraform apply
```

### **4. Access Your Deployment**

```bash
# View outputs
terraform output

# Example outputs:
# web_ui_url = "https://d1234567890.cloudfront.net"
# api_endpoint = "https://abcdef.appsync-api.us-east-1.amazonaws.com/graphql"
# input_bucket = "my-idp-input-documents-abc123"
```

## üìä Analytics and Reporting

When `enable_reporting = true`, you can query analytics data using Amazon Athena:

### **Document-Level Metrics**

```sql
SELECT 
    processor_type,
    AVG(accuracy) as avg_accuracy,
    AVG(f1_score) as avg_f1_score,
    COUNT(*) as document_count
FROM document_evaluations 
WHERE year = 2024 AND month = 7
GROUP BY processor_type;
```

### **Cost Analysis**

```sql
SELECT 
    processor_type,
    SUM(cost_usd) as total_cost,
    AVG(processing_time_ms) as avg_processing_time
FROM metering 
WHERE year = 2024 AND month = 7
GROUP BY processor_type;
```

## üîç Troubleshooting

### **Common Issues**

#### **Model Access Denied**

```
Error: AccessDeniedException: You don't have access to the model
```

**Solution**: Enable model access in Bedrock console

#### **Insufficient Permissions**

```
Error: User is not authorized to perform: bedrock:InvokeModel
```

**Solution**: Ensure AWS credentials have required permissions

#### **Resource Limits**

```
Error: LimitExceededException: Rate exceeded
```

**Solution**: Adjust `max_processing_concurrency` in configuration

### **Getting Help**

- Check CloudWatch logs for detailed error information
- Review module README files for specific guidance
- Verify all prerequisites are met
- Ensure service quotas are adequate

## üéâ What's New

### **v0.3.8 Functional Parity**

- ‚úÖ **Assessment Functions**: Document quality measurement
- ‚úÖ **Enhanced Evaluation**: Baseline comparison with configurable models
- ‚úÖ **Reporting Environment**: Parquet-based analytics with Glue tables
- ‚úÖ **Save Reporting Data**: Automated metrics collection
- ‚úÖ **Enhanced Monitoring**: Comprehensive CloudWatch integration
- ‚úÖ **Conditional Resources**: Optional feature deployment
- ‚úÖ **Environment Variable Parity**: 100% CDK compatibility

### **Deployment Ready**

All examples are now **production-ready** with:

- Complete IAM permission sets
- KMS encryption support
- VPC deployment options
- Comprehensive error handling
- Dead letter queues for reliability
- Auto-scaling configurations

Each example can be deployed independently with just `terraform init && terraform apply` after configuring `terraform.tfvars`! üöÄ
